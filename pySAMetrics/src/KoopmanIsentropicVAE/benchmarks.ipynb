{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc51f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_models.py\n",
    "import os, re, glob, json, csv, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "# removed t-SNE usage per request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92a8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= USER CONFIG =========\n",
    "DATA_PATH  = \"/Volumes/LaCie/000_POSTDOC_2025/long_high_res/smoothed_masked_log.npy\"\n",
    "#BENCH_DIR  = \"/Volumes/LaCie/000_POSTDOC_2025/long_high_res/benchmarks\"\n",
    "BENCH_DIR  = \"/Volumes/LaCie/000_POSTDOC_2025/long_high_res/benchmarks_fixed\"\n",
    "MODELS_DIR = os.path.join(BENCH_DIR, \"models\")\n",
    "OUT_DIR    = os.path.join(BENCH_DIR, \"analysis_comp\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# compare these kinds (order controls plot ordering)\n",
    "KINDS = [\"ae\", \"ae_koop\", \"sae\", \"sae_koop\", \"vae\", \"kvae\",\n",
    "         \"betavae\", \"wae\", \"betatcvae\", \"residualvae\", \"spectralvae\"]\n",
    "# compare these latent dims\n",
    "DIMS  = [4, 8, 16]  # change to [8] or [8,16,32] etc.\n",
    "\n",
    "# heavy ops toggles\n",
    "DECODE_MODES     = True    # decode eigen-modes (needs model.decode/decoder)\n",
    "SHOW_RECON_PANEL = True    # export recon panels\n",
    "DT = 1.0                   # sampling interval for continuous eig conversion\n",
    "\n",
    "# Optional path for coloring PCA/TSNE by organization index (length N array)\n",
    "ORG_INDEX_PATH = os.path.join(BENCH_DIR, \"organization_index.npy\")\n",
    "# Path for organization index based on data_evolution_pw\n",
    "PW_INDEX_PATH = '/Volumes/LaCie/000_POSTDOC_2025/long_high_res/var_pw.npy'\n",
    "\n",
    "# ========= GRID / TRANSFORMS (adjust to your data) =========\n",
    "#nx, ny = 48, 48\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "path_input = '/Volumes/LaCie/000_POSTDOC_2025/long_high_res/reshaped_rho_w_sum.npy'\n",
    "# ========== LOAD AND CENTER DATA (for vis back-transform) ==========\n",
    "plot_data = np.load(path_input)  # Shape: (T, 48, 48)\n",
    "mean_data = plot_data.mean(axis=0)   # Center each pixel over time\n",
    "\n",
    "# --- Helper Function: Convert Flat Tensor to Image ---\n",
    "valid_indices_path = '/Volumes/LaCie/000_POSTDOC_2025/long_high_res/valid_indices.npy'\n",
    "valid_indices = np.load(valid_indices_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a373cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_from_flat_tensor(x, valid_indices=valid_indices):\n",
    "    images = np.zeros((x.shape[0], 48*48))\n",
    "    images[:, valid_indices] = x\n",
    "    images = images.reshape(-1, 48, 48)\n",
    "    return images\n",
    "\n",
    "def infer_grid(D):\n",
    "    # return factor pair (nx, ny) with shape closest to square\n",
    "    best = None\n",
    "    for ny in range(1, int(np.sqrt(D)) + 1):\n",
    "        if D % ny == 0:\n",
    "            nx = D // ny\n",
    "            cand = (nx, ny)\n",
    "            if best is None or abs(nx - ny) < abs(best[0] - best[1]):\n",
    "                best = cand\n",
    "    return best\n",
    "\n",
    "def inv_log_signed(x):  # optional pretty transform\n",
    "    return np.sign(x) * (np.exp(np.abs(x)) - 1)\n",
    "\n",
    "def try_load_org_index(N_total):\n",
    "    if os.path.exists(ORG_INDEX_PATH):\n",
    "        arr = np.load(ORG_INDEX_PATH)\n",
    "        if len(arr) >= N_total:\n",
    "            return arr\n",
    "    return None\n",
    "\n",
    "def try_load_pw_index(N_total):\n",
    "    \"\"\"Load organization index from data_evolution_pw and crop to match data length\"\"\"\n",
    "    if os.path.exists(PW_INDEX_PATH):\n",
    "        arr = np.load(PW_INDEX_PATH)\n",
    "        if len(arr) >= N_total:\n",
    "            return arr[:N_total]  # Crop to match data length\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b04dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= MODELS =========\n",
    "from model import VAE\n",
    "from autoencoder_simple import AE, StochasticAE\n",
    "from additional_models import BetaVAE, WAE, BetaTCVAE, ResidualVAE, SpectralVAE\n",
    "\n",
    "def device_auto():\n",
    "    return torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                        else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_model_class(kind):\n",
    "    if kind in (\"ae\", \"ae_koop\"):\n",
    "        return AE\n",
    "    if kind in (\"sae\", \"sae_koop\"):\n",
    "        return StochasticAE\n",
    "    if kind == \"betavae\":\n",
    "        return BetaVAE\n",
    "    if kind == \"wae\":\n",
    "        return WAE\n",
    "    if kind == \"betatcvae\":\n",
    "        return BetaTCVAE\n",
    "    if kind == \"residualvae\":\n",
    "        return ResidualVAE\n",
    "    if kind == \"spectralvae\":\n",
    "        return SpectralVAE\n",
    "    return VAE  # \"vae\", \"kvae\"\n",
    "\n",
    "def parse_outputs(out):\n",
    "    # Normalize forward outputs across AE/SAE/VAE\n",
    "    if not isinstance(out, (tuple, list)):\n",
    "        return out, out, None, None\n",
    "    if len(out) == 2:     # (recon, z)\n",
    "        recon, z = out\n",
    "        return recon, z, None, None\n",
    "    if len(out) == 3:     # (recon, mu, logvar)\n",
    "        recon, mu, logvar = out\n",
    "        return recon, mu, mu, logvar\n",
    "    recon, z, mu, logvar = out[:4]\n",
    "    code = mu if mu is not None else z\n",
    "    return recon, code, mu, logvar\n",
    "\n",
    "def infer_kind_and_dim(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    m_dim = re.search(r\"_d(\\d+)\\.pt$\", base)\n",
    "    d = int(m_dim.group(1)) if m_dim else None\n",
    "    kind = base.split(\"_d\")[0]\n",
    "    return kind, d\n",
    "\n",
    "def complex_mode_indices(w, tol=1e-10):\n",
    "    \"\"\"Return indices of eigenvalues with positive imaginary part (one per conj pair).\"\"\"\n",
    "    w = np.asarray(w)\n",
    "    return [i for i in range(len(w)) if np.imag(w[i]) > tol]\n",
    "\n",
    "def mode_rms_std(Z, v, center=None):\n",
    "    \"\"\"\n",
    "    RMS std of the complex projection (Z - center) @ v.\n",
    "    Uses sqrt( Var(Re) + Var(Im) ).\n",
    "    \"\"\"\n",
    "    if center is None:\n",
    "        center = Z.mean(axis=0)\n",
    "    alpha = (Z - center) @ v  # complex series length T\n",
    "    return np.sqrt(np.var(alpha.real) + np.var(alpha.imag))\n",
    "\n",
    "def make_orbit(lambda_i, v_i, center, steps=400, scale=1.0, unit_circle=True):\n",
    "    \"\"\"\n",
    "    Build latent orbits along eigenvector v_i:\n",
    "      X0 = scale * v_i\n",
    "      z_t = (λ_i^t) * X0\n",
    "    Returns: (traj_real_plus_center, traj_imag_plus_center), both (steps, d) real arrays.\n",
    "    \"\"\"\n",
    "    steps = int(max(10, round(steps)))\n",
    "    lam = lambda_i / np.abs(lambda_i) if unit_circle else lambda_i  # normalize to unit circle if requested\n",
    "    X0 = v_i * scale\n",
    "    t = np.arange(steps, dtype=np.int64)\n",
    "    lam_t = lam ** t[:, None]                 # (steps, 1) complex\n",
    "    traj = lam_t * X0[None, :]                # (steps, d) complex\n",
    "    return (traj.real + center), (traj.imag + center)  # both real (steps, d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ce8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred grid: nx=40, ny=39  (nx*ny=1560 == D=1560)\n"
     ]
    }
   ],
   "source": [
    "# ========= DATA =========\n",
    "device = device_auto()\n",
    "data = np.load(DATA_PATH)\n",
    "D = data.shape[1]\n",
    "nx, ny = infer_grid(D)\n",
    "print(f\"Inferred grid: nx={nx}, ny={ny}  (nx*ny={nx*ny} == D={D})\")\n",
    "assert nx * ny == D\n",
    "assert D == nx*ny, f\"nx*ny={nx*ny} must match data dim {D}\"\n",
    "N = len(data)\n",
    "train_end = int(0.95 * N)\n",
    "val_end   = train_end + int(0.025 * N)\n",
    "train_np  = data[:train_end].copy()\n",
    "val_np    = data[train_end:val_end].copy()\n",
    "test_np   = data[val_end:].copy()\n",
    "train_tensor = torch.tensor(train_np, dtype=torch.float32)\n",
    "val_tensor   = torch.tensor(val_np, dtype=torch.float32)\n",
    "test_tensor  = torch.tensor(test_np, dtype=torch.float32)\n",
    "org_index = try_load_org_index(N)\n",
    "pw_index = try_load_pw_index(N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c794afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= UTILITIES =========\n",
    "def forward_reconstruct(model, x_tensor, device):\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    with torch.no_grad():\n",
    "        for (xb,) in DataLoader(TensorDataset(x_tensor), batch_size=256, shuffle=False):\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb)\n",
    "            recon, _, _, _ = parse_outputs(out)\n",
    "            outs.append(recon.detach().cpu())\n",
    "    return torch.cat(outs, dim=0).numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_latents(model, x_tensor, device):\n",
    "    Zs = []\n",
    "    for (xb,) in DataLoader(TensorDataset(x_tensor), batch_size=256, shuffle=False):\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        _, code, mu, _ = parse_outputs(out)\n",
    "        Zs.append((mu if mu is not None else code).detach().cpu().numpy())\n",
    "    return np.concatenate(Zs, axis=0)  # (T, d)\n",
    "\n",
    "def fit_linear_A_from_Z(Z, ridge=1e-6, center=True, return_center=True):\n",
    "    \"\"\"\n",
    "    Regress Z_{t+1} on Z_t **after removing the time mean** (anomalies).\n",
    "    Returns A, eigvals, eigvecs, and the time-mean (if requested).\n",
    "    \"\"\"\n",
    "    if center:\n",
    "        Z_mean = Z.mean(axis=0, keepdims=True)\n",
    "        Zc = Z - Z_mean\n",
    "    else:\n",
    "        Z_mean = np.zeros((1, Z.shape[1]), dtype=Z.dtype)\n",
    "        Zc = Z\n",
    "\n",
    "    X, Y = Zc[:-1], Zc[1:]                       # anomalies only\n",
    "    d = Z.shape[1]\n",
    "    A = np.linalg.pinv(X.T @ X + ridge*np.eye(d)) @ (X.T @ Y)   # (d,d)\n",
    "    w, V = np.linalg.eig(A)\n",
    "    if return_center:\n",
    "        return A, w, V, Z_mean.squeeze()\n",
    "    return A, w, V\n",
    "\n",
    "def calculate_explained_variance(Z, V):\n",
    "    \"\"\"Explained variance of each eigenvector using **centered** latents.\"\"\"\n",
    "    Zc = Z - Z.mean(axis=0, keepdims=True)\n",
    "    total_var = np.sum(np.linalg.norm(Zc, axis=1) ** 2)\n",
    "    explained_variance = []\n",
    "\n",
    "    for i in range(V.shape[1]):\n",
    "        v_i = V[:, i]\n",
    "        if np.iscomplexobj(v_i):\n",
    "            # treat real/imag projections\n",
    "            pR = Zc @ v_i.real\n",
    "            pI = Zc @ v_i.imag\n",
    "            mode_power = np.sum(pR**2) + np.sum(pI**2)\n",
    "        else:\n",
    "            p = Zc @ v_i\n",
    "            mode_power = np.sum(p**2)\n",
    "        explained_variance.append(mode_power / (total_var + 1e-12))\n",
    "    return np.array(explained_variance)\n",
    "\n",
    "def discrete_to_continuous(w, dt=1.0):\n",
    "    eps = 1e-12\n",
    "    lam = np.log(np.clip(np.abs(w), eps, None)) / dt + 1j * (np.angle(w) / dt)\n",
    "    return lam, lam.real, lam.imag / (2*np.pi)\n",
    "\n",
    "def cmplx_unit_circle(ax=None):\n",
    "    t = np.linspace(0, 2*np.pi, 400)\n",
    "    u = np.exp(1j*t)\n",
    "    ax = ax or plt.gca()\n",
    "    ax.plot(u.real, u.imag, \"--\", lw=1)\n",
    "    return ax\n",
    "\n",
    "def to_img(x_flat): return x_flat.reshape(ny, nx)\n",
    "\n",
    "def remove_mean(x):\n",
    "    # remove per-sample spatial mean across features\n",
    "    return x - x.mean(axis=1, keepdims=True)\n",
    "\n",
    "def plot_training_curves(tag, losses_path, out_dir):\n",
    "    try:\n",
    "        with open(losses_path, \"rb\") as f:\n",
    "            logs = pickle.load(f)\n",
    "        train_hist = logs.get(\"train_hist\", [])\n",
    "        val_hist   = logs.get(\"val_hist\", [])\n",
    "        # per-model quick export (kept simple)\n",
    "        keys = [\"recon\", \"kl\", \"koop\", \"koop_diag\"]\n",
    "        for k in keys:\n",
    "            if len(train_hist)==0 or k not in train_hist[0]:\n",
    "                continue\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot([e[k] for e in train_hist], label=\"train\")\n",
    "            if len(val_hist)>0 and k in val_hist[0]:\n",
    "                plt.plot([e[k] for e in val_hist], label=\"val\")\n",
    "            plt.title(f\"{tag} · {k}\")\n",
    "            plt.xlabel(\"epoch\"); plt.ylabel(k)\n",
    "            plt.legend(); plt.tight_layout()\n",
    "            plt.savefig(os.path.join(out_dir, f\"{tag}_curve_{k}.png\"), dpi=140)\n",
    "            plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"  (skip curves) {e}\")\n",
    "\n",
    "def load_training_logs(losses_path):\n",
    "    try:\n",
    "        with open(losses_path, \"rb\") as f:\n",
    "            logs = pickle.load(f)\n",
    "        return logs.get(\"train_hist\", []), logs.get(\"val_hist\", [])\n",
    "    except Exception:\n",
    "        return [], []\n",
    "\n",
    "def plot_comparison_curves(all_logs_by_dim_kind, keys, out_dir):\n",
    "    # fixed color per model kind\n",
    "    kind_palette = {\n",
    "        \"ae\": \"#1f77b4\", \"ae_koop\": \"#ff7f0e\", \"sae\": \"#2ca02c\", \"sae_koop\": \"#d62728\",\n",
    "        \"vae\": \"#9467bd\", \"kvae\": \"#8c564b\", \"betavae\": \"#e377c2\", \"wae\": \"#7f7f7f\",\n",
    "        \"betatcvae\": \"#bcbd22\", \"residualvae\": \"#17becf\", \"spectralvae\": \"#393b79\",\n",
    "    }\n",
    "    for d, kind_to_logs in all_logs_by_dim_kind.items():\n",
    "        for k in keys:\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            has_any = False\n",
    "            for kind, logs in kind_to_logs.items():\n",
    "                train_hist, val_hist = logs\n",
    "                first_train_keys = train_hist[0].keys() if len(train_hist)>0 else {}\n",
    "                first_val_keys = val_hist[0].keys() if len(val_hist)>0 else {}\n",
    "                color = kind_palette.get(kind, None)\n",
    "                # special-case for Koopman: plot 0 if not present\n",
    "                if (k not in first_train_keys) and (k not in first_val_keys):\n",
    "                    if k == \"koop\":\n",
    "                        plt.plot([0, 1], [0, 0], label=f\"{kind} · train (0)\", color=color, alpha=0.9)\n",
    "                        has_any = True\n",
    "                    # skip otherwise\n",
    "                    continue\n",
    "                if len(train_hist)>0 and k in first_train_keys:\n",
    "                    plt.plot([e[k] for e in train_hist], label=f\"{kind} · train\", alpha=0.9, color=color)\n",
    "                    has_any = True\n",
    "                if len(val_hist)>0 and k in first_val_keys:\n",
    "                    plt.plot([e[k] for e in val_hist], label=f\"{kind} · val\", ls=\"--\", alpha=0.9, color=color)\n",
    "                    has_any = True\n",
    "            if not has_any:\n",
    "                plt.close()\n",
    "                continue\n",
    "            title = f\"d={d} · {k}\"\n",
    "            if k == \"koop\":\n",
    "                title += \" (actual Koopman loss; 0 for AE/VAE)\"\n",
    "            if k == \"koop_diag\":\n",
    "                title += \" (diagnostic)\"\n",
    "            plt.title(title)\n",
    "            plt.xlabel(\"epoch\"); plt.ylabel(k)\n",
    "            plt.legend(fontsize=8)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(out_dir, f\"comp_curves_{k}_d{d}.png\"), dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "def pca_scatter(Z, title, outpath, colors=None):\n",
    "    pca = PCA(n_components=2).fit(Z)\n",
    "    Z2 = pca.transform(Z)\n",
    "    plt.figure(figsize=(5.5,5))\n",
    "    if colors is None:\n",
    "        plt.scatter(Z2[:,0], Z2[:,1], s=6, alpha=0.7)\n",
    "    else:\n",
    "        sc = plt.scatter(Z2[:,0], Z2[:,1], c=colors, s=6, cmap=\"viridis\", alpha=0.85)\n",
    "        plt.colorbar(sc, label=\"organization index\", aspect=110, shrink=0.6)\n",
    "    plt.title(title); plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150); plt.close()\n",
    "\n",
    "# t-SNE removed per request\n",
    "\n",
    "def decode_modes(model, Z_mean, V, eps=0.5, device=\"cpu\"):\n",
    "    has_decode = hasattr(model, \"decode\")\n",
    "    has_decoder = hasattr(model, \"decoder\")\n",
    "    if not (has_decode or has_decoder):\n",
    "        raise AttributeError(\"Model has no .decode or .decoder\")\n",
    "    modes = []\n",
    "    with torch.no_grad():\n",
    "        for k in range(V.shape[1]):\n",
    "            v = V[:, k].real\n",
    "            v = v / (np.linalg.norm(v) + 1e-12)\n",
    "            z_plus  = torch.tensor(Z_mean + eps*v, dtype=torch.float32, device=device)[None, :]\n",
    "            z_minus = torch.tensor(Z_mean - eps*v, dtype=torch.float32, device=device)[None, :]\n",
    "            x_plus  = model.decode(z_plus)  if has_decode  else model.decoder(z_plus)\n",
    "            x_minus = model.decode(z_minus) if has_decode  else model.decoder(z_minus)\n",
    "            diff = (x_plus - x_minus).detach().cpu().numpy()[0] / (2*eps)\n",
    "            modes.append(diff)\n",
    "    return np.stack(modes, axis=0)\n",
    "\n",
    "def save_eigenvalues_table(tag, w, out_dir):\n",
    "    rows = []\n",
    "    for mu in w:\n",
    "        rows.append([\n",
    "            f\"{mu.real:.5f}\",\n",
    "            f\"{mu.imag:.5f}\",\n",
    "            f\"{np.abs(mu):.5f}\",\n",
    "            f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n",
    "        ])\n",
    "    headers = [\"Re(μ)\", \"Im(μ)\", \"|μ|\", \"freq (cycles/step)\"]\n",
    "    fig, ax = plt.subplots(figsize=(6, min(0.35*len(rows)+1.5, 12)))\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=rows, colLabels=headers, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.2)\n",
    "    ax.set_title(f\"{tag} eigenvalues\")\n",
    "    fig.tight_layout()\n",
    "    out_path = os.path.join(out_dir, f\"{tag}_eigenvalues_table.png\")\n",
    "    fig.savefig(out_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdbf05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Analyzing ae_d16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 32.68 time steps (λ = 0.898+0.175j)\n",
      "    Mode 2: 77.07 time steps (λ = 0.955+0.078j)\n",
      "    Mode 4: 129.76 time steps (λ = 0.948+0.046j)\n",
      "    Mode 7: 566.16 time steps (λ = 0.946+0.011j)\n",
      "    Mode 11: 596.48 time steps (λ = 0.989+0.010j)\n",
      "\n",
      "▶ Analyzing ae_d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 683.08 time steps (λ = 0.995+0.009j)\n",
      "\n",
      "▶ Analyzing ae_d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 84.69 time steps (λ = 0.963+0.072j)\n",
      "    Mode 2: 335.47 time steps (λ = 0.987+0.018j)\n",
      "\n",
      "▶ Analyzing ae_koop_d16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 30.94 time steps (λ = 0.886+0.183j)\n",
      "    Mode 2: 70.25 time steps (λ = 0.953+0.085j)\n",
      "    Mode 4: 118.82 time steps (λ = 0.944+0.050j)\n",
      "    Mode 6: 209.57 time steps (λ = 0.929+0.028j)\n",
      "    Mode 8: 484.37 time steps (λ = 0.954+0.012j)\n",
      "    Mode 11: 611.78 time steps (λ = 0.989+0.010j)\n",
      "\n",
      "▶ Analyzing ae_koop_d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 1045.20 time steps (λ = 0.995+0.006j)\n",
      "\n",
      "▶ Analyzing ae_koop_d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 146.22 time steps (λ = 0.971+0.042j)\n",
      "    Mode 2: 363.06 time steps (λ = 0.986+0.017j)\n",
      "  Creating reconstructed modes for ae_koop_d8 (dim=8)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:254: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.1, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> ae_koop_d8_reconstructed_modes.png\n",
      "\n",
      "▶ Analyzing kvae_d16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 27.41 time steps (λ = 0.849+0.198j)\n",
      "    Mode 2: 77.37 time steps (λ = 0.936+0.076j)\n",
      "    Mode 4: 77.87 time steps (λ = 0.951+0.077j)\n",
      "    Mode 6: 268.50 time steps (λ = 0.924+0.022j)\n",
      "    Mode 8: 940.45 time steps (λ = 0.958+0.006j)\n",
      "    Mode 11: 580.85 time steps (λ = 0.989+0.011j)\n",
      "\n",
      "▶ Analyzing kvae_d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 1: 1583.57 time steps (λ = 0.997+0.004j)\n",
      "\n",
      "▶ Analyzing kvae_d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 90.77 time steps (λ = 0.963+0.067j)\n",
      "    Mode 2: 395.90 time steps (λ = 0.986+0.016j)\n",
      "  Creating reconstructed modes for kvae_d8 (dim=8)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:254: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.1, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> kvae_d8_reconstructed_modes.png\n",
      "\n",
      "▶ Analyzing sae_d16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 33.22 time steps (λ = 0.891+0.171j)\n",
      "    Mode 2: 74.58 time steps (λ = 0.955+0.081j)\n",
      "    Mode 4: 104.04 time steps (λ = 0.925+0.056j)\n",
      "    Mode 7: 563.14 time steps (λ = 0.989+0.011j)\n",
      "    Mode 13: 922.98 time steps (λ = 0.961+0.007j)\n",
      "\n",
      "▶ Analyzing sae_d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 877.94 time steps (λ = 0.995+0.007j)\n",
      "\n",
      "▶ Analyzing sae_d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 140.03 time steps (λ = 0.971+0.044j)\n",
      "    Mode 2: 360.35 time steps (λ = 0.983+0.017j)\n",
      "    Mode 5: 10631.55 time steps (λ = 0.996+0.001j)\n",
      "\n",
      "▶ Analyzing sae_koop_d16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 18.25 time steps (λ = 0.793+0.284j)\n",
      "    Mode 2: 60.82 time steps (λ = 0.957+0.099j)\n",
      "    Mode 4: 81.88 time steps (λ = 0.907+0.070j)\n",
      "    Mode 6: 305.72 time steps (λ = 0.932+0.019j)\n",
      "    Mode 8: 337.24 time steps (λ = 0.948+0.018j)\n",
      "    Mode 11: 752.80 time steps (λ = 0.992+0.008j)\n",
      "\n",
      "▶ Analyzing sae_koop_d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 983.78 time steps (λ = 0.998+0.006j)\n",
      "\n",
      "▶ Analyzing sae_koop_d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 51.79 time steps (λ = 0.960+0.117j)\n",
      "    Mode 2: 353.00 time steps (λ = 0.989+0.018j)\n",
      "\n",
      "▶ Analyzing vae_d16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 33.10 time steps (λ = 0.894+0.172j)\n",
      "    Mode 2: 76.01 time steps (λ = 0.950+0.079j)\n",
      "    Mode 4: 291.95 time steps (λ = 0.924+0.020j)\n",
      "    Mode 6: 128.02 time steps (λ = 0.955+0.047j)\n",
      "    Mode 11: 599.26 time steps (λ = 0.988+0.010j)\n",
      "\n",
      "▶ Analyzing vae_d4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 1033.67 time steps (λ = 0.994+0.006j)\n",
      "\n",
      "▶ Analyzing vae_d8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/1444126032.py:194: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  f\"{(2*np.pi)/np.absolute(np.angle(mu)):.2f}\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orbit times for complex modes:\n",
      "    Mode 0: 217.09 time steps (λ = 0.972+0.028j)\n",
      "    Mode 2: 384.04 time steps (λ = 0.984+0.016j)\n",
      "    Mode 6: 14507.47 time steps (λ = 0.996+0.000j)\n",
      "  Creating reconstructed modes for vae_d8 (dim=8)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/45783546.py:254: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.1, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> vae_d8_reconstructed_modes.png\n"
     ]
    }
   ],
   "source": [
    "# ========= GATHER CHECKPOINTS (filtered) =========\n",
    "all_ckpts = sorted(glob.glob(os.path.join(MODELS_DIR, \"*.pt\")))\n",
    "ckpts = []\n",
    "for p in all_ckpts:\n",
    "    kind, d = infer_kind_and_dim(p)\n",
    "    if kind in KINDS and (d in DIMS):\n",
    "        ckpts.append((p, kind, d))\n",
    "if not ckpts:\n",
    "    raise FileNotFoundError(f\"No checkpoints matching kinds={KINDS} dims={DIMS} in {MODELS_DIR}\")\n",
    "\n",
    "# ========= ANALYZE & COLLECT SUMMARY =========\n",
    "rows = []  # for CSV/summary\n",
    "by_dim = {d: [] for d in DIMS}\n",
    "\n",
    "for mpath, kind, d in ckpts:\n",
    "    tag = os.path.splitext(os.path.basename(mpath))[0]\n",
    "    print(f\"\\n▶ Analyzing {tag}\")\n",
    "\n",
    "    ModelCls = get_model_class(kind)\n",
    "    if kind == \"betavae\":\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d, beta=4.0).to(device)\n",
    "    elif kind == \"wae\":\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d, lambda_mmd=10.0).to(device)\n",
    "    elif kind == \"betatcvae\":\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d, beta=1.0, gamma=1.0).to(device)\n",
    "    else:\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d).to(device)\n",
    "    state = torch.load(mpath, map_location=\"cpu\")\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    # --- Training curves ---\n",
    "    logs_tag = f\"{kind}_d{d}\"\n",
    "    losses_path = os.path.join(BENCH_DIR, \"logs\", f\"{logs_tag}_losses.pkl\")\n",
    "    plot_training_curves(tag, losses_path, OUT_DIR)\n",
    "    # collect logs for later comparative panels\n",
    "    if 'all_logs_by_dim_kind' not in globals():\n",
    "        all_logs_by_dim_kind = {dd: {} for dd in DIMS}\n",
    "    all_logs_by_dim_kind[d][kind] = load_training_logs(losses_path)\n",
    "\n",
    "    # --- Reconstruction (TEST) raw and mean-removed ---\n",
    "    recons = forward_reconstruct(model, test_tensor, device)\n",
    "    err = recons - test_np\n",
    "    mse = float((err**2).mean())\n",
    "    mae = float(np.abs(err).mean())\n",
    "    # mean-removed\n",
    "    test_np_zm = remove_mean(test_np)\n",
    "    recons_zm  = remove_mean(recons)\n",
    "    err_zm = recons_zm - test_np_zm\n",
    "    mse_zm = float((err_zm**2).mean())\n",
    "    mae_zm = float(np.abs(err_zm).mean())\n",
    "\n",
    "    # --- Latents (TRAIN) -> Koopman A & eigs\n",
    "    Z_train = collect_latents(model, train_tensor, device)   # (T_train, d)\n",
    "    A, w, V, Z0 = fit_linear_A_from_Z(Z_train, ridge=1e-6, center=True, return_center=True)\n",
    "    lam, growth, freq_hz = discrete_to_continuous(w, dt=DT)\n",
    "    rho = float(np.max(np.abs(w)))\n",
    "    p_stable = float((np.abs(w) < 1.0).mean())\n",
    "\n",
    "    # --- PCA & t-SNE on TRAIN (colored by PW or ORG index if present)\n",
    "    if pw_index is not None:\n",
    "        org_train = pw_index[:train_end]\n",
    "        org_val   = pw_index[train_end:val_end]\n",
    "        org_test  = pw_index[val_end:]\n",
    "    elif org_index is not None:\n",
    "        org_train = org_index[:train_end]\n",
    "        org_val   = org_index[train_end:val_end]\n",
    "        org_test  = org_index[val_end:]\n",
    "    else:\n",
    "        org_train = org_val = org_test = None\n",
    "\n",
    "    pca_scatter(Z_train, f\"{tag} PCA (train)\",\n",
    "                os.path.join(OUT_DIR, f\"{tag}_pca_train.png\"),\n",
    "                colors=org_train)\n",
    "    # t-SNE removed per request\n",
    "\n",
    "    # --- Calculate Explained Variance ---\n",
    "    explained_var = calculate_explained_variance(Z_train, V)\n",
    "\n",
    "\n",
    "\n",
    "    # --- Eigenvalue Phase Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    ax.plot(np.cos(theta), np.sin(theta), 'k--', alpha=0.5, label='Unit circle')\n",
    "    scatter = ax.scatter(w.real, w.imag, s=100, c=explained_var,\n",
    "                         cmap='viridis', alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "    cbar = plt.colorbar(scatter, ax=ax, orientation='horizontal', aspect=110, shrink=0.6)\n",
    "    cbar.set_label('Explained Variance')\n",
    "    ax.set_xlabel('Real part')\n",
    "    ax.set_ylabel('Imaginary part')\n",
    "    ax.set_title(f'{tag} Eigenvalue Phase Plot')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal')\n",
    "    fig.tight_layout()\n",
    "    eig_phase_path = os.path.join(OUT_DIR, f\"{tag}_eigenvalue_phase.png\")\n",
    "    fig.savefig(eig_phase_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Zoomed eigenvalue plot near unit circle (0.9..1 window)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    ax.plot(np.cos(theta), np.sin(theta), 'k--', alpha=0.5)\n",
    "    ax.scatter(w.real, w.imag, s=60, c=explained_var, cmap='viridis', alpha=0.85, edgecolors='black', linewidth=0.3)\n",
    "    ax.set_xlim(0.9, 1.0)\n",
    "    ax.set_ylim(-0.1, 0.1)\n",
    "    ax.set_xlabel('Real part')\n",
    "    ax.set_ylabel('Imag part')\n",
    "    ax.set_title(f'{tag} eigenvalues (zoom)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(OUT_DIR, f\"{tag}_eigenvalue_phase_zoom.png\"), dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # eigenvalues table image\n",
    "    try:\n",
    "        save_eigenvalues_table(tag, w, OUT_DIR)\n",
    "    except Exception as e:\n",
    "        print(\"  (skip eigenvalue table)\", e)\n",
    "\n",
    "    # --- Print Orbit Times for Complex Modes ---\n",
    "    cidx = complex_mode_indices(w)\n",
    "    print(f\"  Orbit times for complex modes:\")\n",
    "    for i in cidx:\n",
    "        lam_i = w[i]\n",
    "        if np.imag(lam_i) != 0:\n",
    "            period = 2 * np.pi / np.arctan2(np.imag(lam_i), np.real(lam_i))\n",
    "            print(f\"    Mode {i}: {period:.2f} time steps (λ = {lam_i:.3f})\")\n",
    "\n",
    "    # --- Orbits from complex modes: z_t = Re/Im( (λ^t) v ) + mean ---\n",
    "    Z0 = Z_train.mean(axis=0)\n",
    "    if len(cidx) == 0:\n",
    "        print(\"  no complex eigenvalues; skip eigen-orbits\")\n",
    "    else:\n",
    "        # Create orbits for TRAIN PCA plots only\n",
    "        pca_split = PCA(n_components=2).fit(Z_train)\n",
    "        Z2_split = pca_split.transform(Z_train)\n",
    "        for i in cidx:\n",
    "            v_i = V[:, i]                       # complex eigenvector (d,)\n",
    "            v_i = v_i / (np.linalg.norm(v_i) + 1e-12)\n",
    "            sigma_i = mode_rms_std(Z_train, v_i, center=Z0)\n",
    "            scale_i = 2.0 * sigma_i\n",
    "            # approx steps from angle, ensure int\n",
    "            ang = np.angle(w[i])\n",
    "            steps_orbit = 400 if abs(ang) < 1e-6 else max(50, int(round(2*np.pi/abs(ang))))\n",
    "            trajR, trajI = make_orbit(w[i], v_i, Z0, steps=steps_orbit,\n",
    "                                      scale=scale_i, unit_circle=True)\n",
    "            Z2_R = pca_split.transform(trajR)\n",
    "            Z2_I = pca_split.transform(trajI)\n",
    "            fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            if org_train is not None:\n",
    "                sc = ax.scatter(Z2_split[:,0], Z2_split[:,1], c=org_train,\n",
    "                                s=6, cmap=\"viridis\", alpha=0.7)\n",
    "                plt.colorbar(sc, ax=ax, label=\"Organization Index\")\n",
    "            else:\n",
    "                ax.scatter(Z2_split[:,0], Z2_split[:,1], s=6, alpha=0.7, label=\"TRAIN data\")\n",
    "            ax.plot(Z2_R[:,0], Z2_R[:,1], lw=2.0, label=f\"mode {i} · Re(λ^t v)\")\n",
    "            ax.plot(Z2_I[:,0], Z2_I[:,1], lw=2.0, ls=\"--\", label=f\"mode {i} · Im(λ^t v)\")\n",
    "            ax.set_xlabel(\"PC1\"); ax.set_ylabel(\"PC2\")\n",
    "            mag = np.abs(w[i]); ang = np.angle(w[i])\n",
    "            title_bits = f\"|λ|={mag:.3f}, arg={ang:.3f} rad (unit circle)\"\n",
    "            ax.set_title(f\"{tag} eigen-orbit (mode {i}) - TRAIN: {title_bits}\")\n",
    "            ax.legend(loc=\"best\", fontsize=9)\n",
    "            fig.tight_layout()\n",
    "            out_orbit = os.path.join(OUT_DIR, f\"{tag}_orbit_mode{i}_train_pca.png\")\n",
    "            fig.savefig(out_orbit, dpi=160)\n",
    "            plt.close(fig)\n",
    "\n",
    "        # Also save oscillation stacks for complex modes (latent-orbit decoded frames)\n",
    "        try:\n",
    "            dev = next(model.parameters()).device\n",
    "            has_decode = hasattr(model, \"decode\") or hasattr(model, \"decoder\")\n",
    "            if has_decode:\n",
    "                for i in cidx:\n",
    "                    v_i = V[:, i]\n",
    "                    v_i = v_i / (np.linalg.norm(v_i) + 1e-12)\n",
    "                    sigma_i = mode_rms_std(Z_train, v_i, center=Z0)\n",
    "                    scale_i = 2.0 * sigma_i\n",
    "                    steps_vid = 60\n",
    "                    frames = []\n",
    "                    with torch.no_grad():\n",
    "                        for t in range(steps_vid):\n",
    "                            angle = 2*np.pi * (t/steps_vid)\n",
    "                            z_t = Z0 + scale_i * (np.cos(angle)*v_i.real - np.sin(angle)*v_i.imag)\n",
    "                            z_t = torch.tensor(z_t, dtype=torch.float32, device=dev)[None, :]\n",
    "                            x_t = (model.decode(z_t) if hasattr(model, \"decode\") else model.decoder(z_t)).cpu().numpy()[0]\n",
    "                            frames.append(x_t)\n",
    "                    np.save(os.path.join(OUT_DIR, f\"{tag}_oscillation_mode{i}.npy\"), np.stack(frames, axis=0))\n",
    "        except Exception as e:\n",
    "            print(\"  (skip oscillation stacks)\", e)\n",
    "\n",
    "    # --- Reconstructed Modes for dim=8 (optional demo) ---\n",
    "    if DECODE_MODES and d == 8 and kind in (\"ae_koop\", \"vae\", \"kvae\"):\n",
    "        try:\n",
    "            print(f\"  Creating reconstructed modes for {tag} (dim={d})...\")\n",
    "            mean_latent = Z0.copy()\n",
    "            dev = next(model.parameters()).device\n",
    "            sigma_list = []\n",
    "            for i in range(V.shape[1]):\n",
    "                v_i = V[:, i]\n",
    "                sigma_i = mode_rms_std(Z_train, v_i, center=mean_latent)\n",
    "                sigma_list.append(sigma_i)\n",
    "\n",
    "            reconstructed_modes = []\n",
    "            with torch.no_grad():\n",
    "                for i in range(V.shape[1]):\n",
    "                    eigvec = V[:, i] * 2 * sigma_list[i]\n",
    "                    if np.iscomplexobj(eigvec):\n",
    "                        z_real = torch.tensor(mean_latent + np.real(eigvec), dtype=torch.float32, device=dev)[None, :]\n",
    "                        z_imag = torch.tensor(mean_latent + np.imag(eigvec), dtype=torch.float32, device=dev)[None, :]\n",
    "                        real_recon = (model.decode(z_real) if hasattr(model,\"decode\") else model.decoder(z_real)).cpu().numpy()[0]\n",
    "                        imag_recon = (model.decode(z_imag) if hasattr(model,\"decode\") else model.decoder(z_imag)).cpu().numpy()[0]\n",
    "                        reconstructed_modes.append(real_recon)\n",
    "                        reconstructed_modes.append(imag_recon)\n",
    "                    else:\n",
    "                        z_in = torch.tensor(mean_latent + eigvec, dtype=torch.float32, device=dev)[None, :]\n",
    "                        recon = (model.decode(z_in) if hasattr(model,\"decode\") else model.decoder(z_in)).cpu().numpy()[0]\n",
    "                        reconstructed_modes.append(recon)\n",
    "\n",
    "            # Plot reconstructed modes (2 rows, up to 8 columns)\n",
    "            num_cols = min(8, max(1, int(np.ceil(len(reconstructed_modes)/2))))\n",
    "            fig, ax = plt.subplots(2, num_cols, figsize=(2.5*num_cols, 6))\n",
    "            vmin, vmax = -40, 40\n",
    "            x = np.linspace(0, 1, 48)\n",
    "            z_array = np.loadtxt('z_array.txt')\n",
    "            y = z_array[:48] / 1000\n",
    "            XX, YY = np.meshgrid(x, y)\n",
    "            levels = np.concatenate([\n",
    "                np.linspace(-150, -50, 3),\n",
    "                np.linspace(-50, -10, 20),\n",
    "                np.linspace(-10, 10, 50),\n",
    "                np.linspace(10, 50, 20),\n",
    "                np.linspace(50, 150, 3)\n",
    "            ])\n",
    "            levels = np.sort(np.unique(levels))\n",
    "\n",
    "            for i in range(min(len(reconstructed_modes), 16)):\n",
    "                inv_log = inv_log_signed(reconstructed_modes[i])\n",
    "                images = create_image_from_flat_tensor(inv_log[None, :])\n",
    "                img = images[0]\n",
    "                row = 0 if i % 2 == 0 else 1\n",
    "                col = i // 2\n",
    "                ax[row, col].contourf(XX, YY, img, cmap='RdBu_r', levels=levels, vmin=vmin, vmax=vmax)\n",
    "                ax[row, col].set_title(f\"mode {col} {'Re' if row==0 else 'Im'}\")\n",
    "                ax[row, col].grid(True)\n",
    "\n",
    "            from matplotlib.cm import ScalarMappable\n",
    "            import matplotlib.colors as mcolors\n",
    "            cbar_ax = fig.add_axes([0.2, 0.05, 0.6, 0.03])\n",
    "            norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "            sm = ScalarMappable(norm=norm, cmap='RdBu_r'); sm.set_array([])\n",
    "            fig.colorbar(sm, cax=cbar_ax, orientation='horizontal',\n",
    "                         label=r'Isentropic Mass Flux [kg$\\cdot$m/s]')\n",
    "            plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "            fig.savefig(os.path.join(OUT_DIR, f\"{tag}_reconstructed_modes.png\"), dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f\"    -> {tag}_reconstructed_modes.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"  (skip reconstructed modes for {tag})\", e)\n",
    "\n",
    "    # Collect summary row\n",
    "    row = {\n",
    "        \"tag\": tag, \"kind\": kind, \"latent_dim\": d,\n",
    "        \"test_mse\": mse, \"test_mae\": mae,\n",
    "        \"rho\": rho, \"p_stable\": p_stable,\n",
    "        \"growth_max\": float(growth.max()),\n",
    "        \"A_path\": os.path.join(OUT_DIR, f\"{tag}_A.npy\"),\n",
    "        \"eigs_path\": eig_phase_path,\n",
    "        \"pca_train_path\": os.path.join(OUT_DIR, f\"{tag}_pca_train.png\"),\n",
    "        \"tsne_train_path\": os.path.join(OUT_DIR, f\"{tag}_tsne_train.png\"),\n",
    "    }\n",
    "    np.save(row[\"A_path\"], A)\n",
    "    rows.append(row)\n",
    "    by_dim[d].append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc316095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Creating individual reconstruction panels for each model...\n",
      "Random samples: [ 72 244 437  79 402]\n",
      "  Creating reconstruction panel for ae_d16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/3704296704.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(mpath, map_location=\"cpu\")\n",
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/3704296704.py:86: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  figsamp.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> ae_d16_reconstruction_skills.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/zpcrn7ys4y15p92_t65w5_200000gn/T/ipykernel_84478/3704296704.py:109: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  figerr.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> ae_d16_reconstruction_errors.png\n",
      "  Creating reconstruction panel for ae_d4...\n",
      "    -> ae_d4_reconstruction_skills.png\n",
      "    -> ae_d4_reconstruction_errors.png\n",
      "  Creating reconstruction panel for ae_d8...\n",
      "    -> ae_d8_reconstruction_skills.png\n",
      "    -> ae_d8_reconstruction_errors.png\n",
      "  Creating reconstruction panel for ae_koop_d16...\n",
      "    -> ae_koop_d16_reconstruction_skills.png\n",
      "    -> ae_koop_d16_reconstruction_errors.png\n",
      "  Creating reconstruction panel for ae_koop_d4...\n",
      "    -> ae_koop_d4_reconstruction_skills.png\n",
      "    -> ae_koop_d4_reconstruction_errors.png\n",
      "  Creating reconstruction panel for ae_koop_d8...\n",
      "    -> ae_koop_d8_reconstruction_skills.png\n",
      "    -> ae_koop_d8_reconstruction_errors.png\n",
      "  Creating reconstruction panel for kvae_d16...\n",
      "    -> kvae_d16_reconstruction_skills.png\n",
      "    -> kvae_d16_reconstruction_errors.png\n",
      "  Creating reconstruction panel for kvae_d4...\n",
      "    -> kvae_d4_reconstruction_skills.png\n",
      "    -> kvae_d4_reconstruction_errors.png\n",
      "  Creating reconstruction panel for kvae_d8...\n",
      "    -> kvae_d8_reconstruction_skills.png\n",
      "    -> kvae_d8_reconstruction_errors.png\n",
      "  Creating reconstruction panel for sae_d16...\n",
      "    -> sae_d16_reconstruction_skills.png\n",
      "    -> sae_d16_reconstruction_errors.png\n",
      "  Creating reconstruction panel for sae_d4...\n",
      "    -> sae_d4_reconstruction_skills.png\n",
      "    -> sae_d4_reconstruction_errors.png\n",
      "  Creating reconstruction panel for sae_d8...\n",
      "    -> sae_d8_reconstruction_skills.png\n",
      "    -> sae_d8_reconstruction_errors.png\n",
      "  Creating reconstruction panel for sae_koop_d16...\n",
      "    -> sae_koop_d16_reconstruction_skills.png\n",
      "    -> sae_koop_d16_reconstruction_errors.png\n",
      "  Creating reconstruction panel for sae_koop_d4...\n",
      "    -> sae_koop_d4_reconstruction_skills.png\n",
      "    -> sae_koop_d4_reconstruction_errors.png\n",
      "  Creating reconstruction panel for sae_koop_d8...\n",
      "    -> sae_koop_d8_reconstruction_skills.png\n",
      "    -> sae_koop_d8_reconstruction_errors.png\n",
      "  Creating reconstruction panel for vae_d16...\n",
      "    -> vae_d16_reconstruction_skills.png\n",
      "    -> vae_d16_reconstruction_errors.png\n",
      "  Creating reconstruction panel for vae_d4...\n",
      "    -> vae_d4_reconstruction_skills.png\n",
      "    -> vae_d4_reconstruction_errors.png\n",
      "  Creating reconstruction panel for vae_d8...\n",
      "    -> vae_d8_reconstruction_skills.png\n",
      "    -> vae_d8_reconstruction_errors.png\n",
      "\n",
      "Done. You now have per-model figures and per-dim comparison charts + CSV in: /Volumes/LaCie/000_POSTDOC_2025/long_high_res/benchmarks_fixed/analysis_comp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Comparative training curves per dim (beta removed per request)\n",
    "try:\n",
    "    plot_comparison_curves({d: {} for d in DIMS} if 'all_logs_by_dim_kind' not in globals() else all_logs_by_dim_kind,\n",
    "                           keys=[\"recon\", \"kl\", \"koop\", \"koop_diag\"], out_dir=OUT_DIR)\n",
    "except Exception as e:\n",
    "    print(\"(skip comparison curves)\", e)\n",
    "\n",
    "# ========= INDIVIDUAL RECONSTRUCTION PANELS FOR EACH MODEL =========\n",
    "print(\"\\n▶ Creating individual reconstruction panels for each model...\")\n",
    "\n",
    "# Random samples for reconstruction comparison (same for all models)\n",
    "np.random.seed(42)  # For reproducible random samples\n",
    "Nsamp = min(5, len(test_np))\n",
    "samples = np.random.choice(len(test_np), size=Nsamp, replace=False)\n",
    "print(\"Random samples:\", samples)\n",
    "\n",
    "# Create grid for contour plots (use 48x48 to match create_image_from_flat_tensor output)\n",
    "x = np.linspace(0, 1, 48)\n",
    "z_array = np.loadtxt('z_array.txt')\n",
    "y = z_array[:48] / 1000\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "\n",
    "# Define contour levels exactly like your example\n",
    "vmin, vmax = -40, 40\n",
    "levels = np.concatenate([\n",
    "    np.linspace(-150, -50, 3),\n",
    "    np.linspace(-50, -10, 20),\n",
    "    np.linspace(-10, 10, 50),\n",
    "    np.linspace(10, 50, 20),\n",
    "    np.linspace(50, 150, 3)\n",
    "])\n",
    "levels = np.sort(np.unique(levels))\n",
    "\n",
    "# Create individual reconstruction panels for each model\n",
    "for mpath, kind, d in ckpts:\n",
    "    tag = os.path.splitext(os.path.basename(mpath))[0]\n",
    "    print(f\"  Creating reconstruction panel for {tag}...\")\n",
    "\n",
    "    # Load model\n",
    "    ModelCls = get_model_class(kind)\n",
    "    if kind == \"betavae\":\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d, beta=4.0).to(device)\n",
    "    elif kind == \"wae\":\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d, lambda_mmd=10.0).to(device)\n",
    "    elif kind == \"betatcvae\":\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d, beta=1.0, gamma=1.0).to(device)\n",
    "    else:\n",
    "        model = ModelCls(input_dim=D, hidden_dim=512, latent_dim=d).to(device)\n",
    "\n",
    "    state = torch.load(mpath, map_location=\"cpu\")\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    # Get reconstructions\n",
    "    recons = forward_reconstruct(model, test_tensor, device)\n",
    "\n",
    "    figsamp, axs = plt.subplots(2, len(samples), figsize=(30, 19.2))  # 2 rows, Nsamp cols\n",
    "    figsamp.subplots_adjust(wspace=0.3, hspace=-0.3)\n",
    "\n",
    "    cb_plot = None\n",
    "    for i, idx in enumerate(samples):\n",
    "        inv_log = inv_log_signed(test_np[idx])\n",
    "        images = create_image_from_flat_tensor(inv_log[None, :])\n",
    "        origi_img = images[0] + mean_data\n",
    "\n",
    "        inv_log = inv_log_signed(recons[idx])\n",
    "        images = create_image_from_flat_tensor(inv_log[None, :])\n",
    "        recon_img = images[0] + mean_data\n",
    "\n",
    "        cb_plot = axs[0, i].contourf(XX, YY, origi_img, cmap='RdBu_r',\n",
    "                                     levels=levels, vmin=vmin, vmax=vmax)\n",
    "        axs[0, i].set_title(f\"Original #{idx}\")\n",
    "        axs[0, i].grid(True)\n",
    "\n",
    "        cb_plot = axs[1, i].contourf(XX, YY, recon_img, cmap='RdBu_r',\n",
    "                                     levels=levels, vmin=vmin, vmax=vmax)\n",
    "        axs[1, i].set_title(f\"Reconstruction #{idx}\")\n",
    "        axs[1, i].grid(True)\n",
    "\n",
    "    if cb_plot is not None:\n",
    "        cbar = figsamp.colorbar(cb_plot, ax=axs.ravel().tolist(),\n",
    "                                orientation='horizontal', shrink=0.8, pad=-0.5, aspect=110)\n",
    "        cbar.set_label(r'Isentropic Mass Flux [kg$\\cdot$m/s]')\n",
    "\n",
    "    figsamp.suptitle(f\"{tag} Reconstruction Skills\", fontsize=16, y=0.98)\n",
    "    figsamp.tight_layout()\n",
    "    figsamp.savefig(os.path.join(OUT_DIR, f\"{tag}_reconstruction_skills.png\"),\n",
    "                    dpi=150, bbox_inches='tight')\n",
    "    plt.close(figsamp)\n",
    "    print(f\"    -> {tag}_reconstruction_skills.png\")\n",
    "\n",
    "    # Difference (prediction - test) panel to highlight model errors\n",
    "    figerr, axerr = plt.subplots(1, len(samples), figsize=(30, 8.65))\n",
    "    figerr.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "    cb_plot2 = None\n",
    "    for i, idx in enumerate(samples):\n",
    "        inv_log_o = inv_log_signed(test_np[idx])\n",
    "        inv_log_r = inv_log_signed(recons[idx])\n",
    "        img_o = create_image_from_flat_tensor(inv_log_o[None, :])[0] + mean_data\n",
    "        img_r = create_image_from_flat_tensor(inv_log_r[None, :])[0] + mean_data\n",
    "        diff_img = img_r - img_o\n",
    "        cb_plot2 = axerr[i].contourf(XX, YY, diff_img, cmap='RdBu_r', levels=levels, vmin=vmin, vmax=vmax)\n",
    "        axerr[i].set_title(f\"Error #{idx} (recon - orig)\")\n",
    "        axerr[i].grid(True)\n",
    "    if cb_plot2 is not None:\n",
    "        cbar2 = figerr.colorbar(cb_plot2, ax=axerr.ravel().tolist(), orientation='horizontal', shrink=0.8, pad=0.05, aspect=110)\n",
    "        cbar2.set_label(r'Isentropic Mass Flux error [kg$\\cdot$m/s]')\n",
    "    figerr.suptitle(f\"{tag} Reconstruction Errors\", fontsize=16, y=0.98)\n",
    "    figerr.tight_layout()\n",
    "    figerr.savefig(os.path.join(OUT_DIR, f\"{tag}_reconstruction_errors.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close(figerr)\n",
    "    print(f\"    -> {tag}_reconstruction_errors.png\")\n",
    "\n",
    "print(\"\\nDone. You now have per-model figures and per-dim comparison charts + CSV in:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada4097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
